---
title: "AutoNE: Hyperparameter Optimization for Massive Network Embedding"
collection: publications
permalink: /publication/2019-08-AutoNE
excerpt: 'Key words: Network Representation Learning; Network Embedding; Automated Machine Learning; Meta-Learning; Hyperparameter Optimization'
date: 2019-08-04
venue: 'KDD'
paperurl: '/files/2019_KDD_AutoNE.pdf'
citation: 'Tu, Ke, et al. "AutoNE: Hyperparameter Optimization for Massive Network Embedding". Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. ACM, 2019.'
---
Network embedding (NE) aims to embed the nodes of a network into a vector space, and serves as the bridge between machine learning and network data.
Despite their widespread success, NE algorithms typically contain a large number of hyperparameters for preserving the various network properties, which must be carefully decided in order to achieve satisfactory performance.
Though automated machine learning (AutoML) has achieved promising results when applied to many types of data such as images and texts, network data pose great challenges to AutoML and remain largely ignored by the literature of AutoML.
The biggest obstacle is the massive scale of real-world networks, along with the coupled node relationships that make any straightforward sampling strategy problematic.
In this paper, we propose a novel framework, named AutoNE, to automatically optimize the hyperparameters of a NE algorithm on massive networks.
In detail, we employ a multi-start random walk strategy to sample several small sub-networks, perform each trial of configuration selection on the sampled sub-network, and design a meta-leaner to transfer the knowledge about optimal hyperparameters from the sub-networks to the original massive network.
The transferred meta-knowledge greatly reduces the number of trials required when predicting the optimal hyperparameters for the original network. Extensive experiments demonstrate that our framework can significantly outperform the existing methods, in that it needs less time and fewer trials to find the optimal hyperparameters.

The code is available on [here](https://github.com/tadpole/AutoNE).

Recommended citation: 
```
@inproceedings{tu2019AutoNE,
  title={AutoNE: Hyperparameter Optimization for Massive Network Embedding},
  author={Ke Tu, Peng Cui, Xiao Wang, Fei Wang, Wenwu Zhu},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  year={2019},
  organization={ACM}
}
```
